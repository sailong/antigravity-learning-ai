import asyncio
import os
# å‡è®¾æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„ LLM åº“ (è¿™é‡Œç”¨ä¼ªä»£ç è¡¨ç¤ºæ ¸å¿ƒé€»è¾‘ï¼Œæ–¹ä¾¿ä½ ç†è§£æµç¨‹)
# from openai import OpenAI 

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# è¿™æ˜¯ä½ çš„ç³»ç»ŸæŒ‡ä»¤ï¼Œèµ‹äºˆ Agent è§’è‰²
# SYSTEM_PROMPT = """
# ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹›è˜ç»ç†ã€‚
# ä½ çš„ç›®æ ‡æ˜¯ç­›é€‰ç®€å†ã€‚
# è¯·ä½¿ç”¨æä¾›çš„å·¥å…·æ¥è¯»å–æ–‡ä»¶åˆ—è¡¨å’Œå†…å®¹ã€‚
# æœ€åè¾“å‡ºä¸€ä¸ªè¯„åˆ†è¡¨æ ¼ã€‚
# """
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹›è˜ç­›é€‰ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æå–ç®€å†çš„å…³é”®ä¿¡æ¯å¹¶æ‰“åˆ†ã€‚

# æ ¸å¿ƒè§„åˆ™
1. ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–åºŸè¯ã€‚
2. æ¯æ¬¡åˆ†æå®Œä¸€ä»½ç®€å†ï¼Œåªè¾“å‡ºè¯¥ç®€å†çš„ç»“æ„åŒ–æ•°æ®ã€‚

# è¯„åˆ†æ ‡å‡† (0-100åˆ†)
- å…³é”®è¯åŒ¹é…: Python, MCP, Agent (æ¯ä¸ª+20åˆ†)
- ç»éªŒ: 3å¹´ä»¥ä¸Š (+20åˆ†)
- å­¦å†: æœ¬ç§‘åŠä»¥ä¸Š (+20åˆ†)

# è¾“å‡ºæ ¼å¼ç¤ºä¾‹
{
    "name": "å€™é€‰äººå§“å",
    "score": 85,
    "skills": ["Python", "MCP"],
    "summary": "ç®€çŸ­è¯„ä»·..."
}
"""

async def run_smart_agent():
    # 1. å¯åŠ¨ MCP Server (å’Œä¹‹å‰ä¸€æ ·)
    server_params = StdioServerParameters(
        command="python", 
        args=["resume_server.py"], 
        env=os.environ.copy()
    )

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            # 2. è·å–å·¥å…· (Hands)
            tools = await session.list_tools()
            print(f"ğŸ”§ æ¿€æ´»å·¥å…·: {[t.name for t in tools.tools]}")

            # 3. åˆå§‹ç”¨æˆ·ä»»åŠ¡
            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": "å¸®æˆ‘ç­›é€‰ä¸€ä¸‹å½“å‰æ–‡ä»¶å¤¹é‡Œçš„ç®€å†ï¼Œæˆ‘è¦æ‰¾æ‡‚ Python çš„äººã€‚"}
            ]

            # --- æ ¸å¿ƒå¾ªç¯ (The Loop) ---
            print("\nğŸ§  Agent å¼€å§‹æ€è€ƒ...")
            
            # è¿™é‡Œæ˜¯ä¸€ä¸ªç®€åŒ–çš„å¾ªç¯é€»è¾‘
            while True:
                # A. è°ƒç”¨ LLM (Brain)
                # response = client.chat.completions.create(model="gpt-4", messages=messages, tools=convert_to_openai_tools(tools))
                
                # å‡è®¾ LLM è¿”å›äº†ï¼š "è¯·è°ƒç”¨ list_resumes()" 
                # (è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿ LLM çš„ç¬¬ä¸€æ¬¡å†³ç­–)
                print("ğŸ¤– LLM å†³å®š: è°ƒç”¨ list_resumes å·¥å…·")
                
                # B. æ‰§è¡Œå·¥å…· (Action)
                # çœŸæ­£çš„ MCP è°ƒç”¨å‘ç”Ÿåœ¨è¿™é‡Œï¼
                tool_name = "list_resumes"
                tool_args = {"directory": "."}
                
                result = await session.call_tool(tool_name, arguments=tool_args)
                tool_output = result.content[0].text
                print(f"ğŸ“„ MCP Server åé¦ˆ: {tool_output}")

                # C. å°†ç»“æœå†™å›å†å²è®°å½• (Memory)
                messages.append({
                    "role": "function", 
                    "name": tool_name, 
                    "content": tool_output
                })

                # D. å†æ¬¡è¯¢é—® LLM
                # LLM çœ‹åˆ°æ–‡ä»¶åˆ—è¡¨åï¼Œä¼šå‘èµ·ç¬¬äºŒæ¬¡è°ƒç”¨ï¼š"è¯»å– resume_1.txt"
                # ... å¾ªç¯ç›´åˆ° LLM è¯´ "å®Œæˆ"
                
                print("âœ¨ (æ¨¡æ‹Ÿç»“æŸ) Agent æ‹¿åˆ°æ–‡ä»¶åˆ—è¡¨åï¼Œä¸‹ä¸€æ­¥å°±ä¼šè‡ªåŠ¨è¯·æ±‚è¯»å–å†…å®¹äº†ã€‚")
                break 

if __name__ == "__main__":
    asyncio.run(run_smart_agent())