import asyncio
import os
import json
import sys
from openai import OpenAI

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

# 1. ç³»ç»ŸæŒ‡ä»¤ï¼šæ˜ç¡® Agent çš„èŒè´£å’Œè¾“å‡ºæ ¼å¼
SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹›è˜ç­›é€‰ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯»å–å€™é€‰äººç®€å†ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œå¹¶æ ¹æ®è¦æ±‚è¿›è¡Œç­›é€‰æ‰“åˆ†ã€‚

# ä½ çš„å·¥ä½œæµç¨‹
1. ä½¿ç”¨ `list_resumes` å·¥å…·æŸ¥çœ‹ `resumes` ç›®å½•ä¸‹çš„æ‰€æœ‰ç®€å†æ–‡ä»¶ã€‚
2. ä½¿ç”¨ `read_resume_content` å·¥å…·è¯»å–ç®€å†å†…å®¹ã€‚ç”±äºä¸Šä¸‹æ–‡é™åˆ¶ï¼Œä½ å¯ä»¥**åªè¯»å–å‰ 3-5 ä»½**åŒ…å« "Python" æˆ– "Tech" å…³é”®è¯çš„ç®€å†è¿›è¡Œæ¼”ç¤ºã€‚
3. åˆ†æç®€å†å†…å®¹ï¼Œæå–ï¼šå§“åã€æŠ€èƒ½ã€å·¥ä½œå¹´é™ã€åŒ¹é…åº¦è¯„åˆ†ã€‚
4. æœ€ç»ˆè¾“å‡ºä¸€ä¸ª JSON åˆ—è¡¨ã€‚

# æ ¸å¿ƒè§„åˆ™
- ä½ å¿…é¡»è¿”å› JSON æ ¼å¼çš„æ•°æ®ã€‚
- ä¸è¦è¿”å› Markdown æ ¼å¼ï¼ˆå¦‚ ```jsonï¼‰ï¼Œç›´æ¥è¿”å›çº¯ JSON å­—ç¬¦ä¸²ã€‚
- è¯„åˆ†æ ‡å‡†ï¼šPython/Go/Java (+20), 3å¹´ä»¥ä¸Šç»éªŒ (+20), æœ¬ç§‘ (+10).

# æœ€ç»ˆè¾“å‡ºç¤ºä¾‹
[
    {
        "filename": "Tech_Python_å¼ ä¸‰.txt",
        "name": "å¼ ä¸‰",
        "score": 85,
        "skills": ["Python", "Django"],
        "reason": "ç»éªŒä¸°å¯Œï¼ŒæŠ€æœ¯æ ˆåŒ¹é…"
    }
]
"""

# 2. é…ç½® LLM å®¢æˆ·ç«¯
client = OpenAI(
    base_url="http://127.0.0.1:33333/v1", 
    api_key="lm-studio"
)

# 3. å·¥å…·æ ¼å¼è½¬æ¢ (MCP -> OpenAI)
def format_mcp_tools_for_openai(mcp_tools):
    openai_tools = []
    for tool in mcp_tools:
        openai_tools.append({
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "parameters": tool.inputSchema
            }
        })
    return openai_tools

# 4. Agent æ ¸å¿ƒæ€è€ƒå¾ªç¯
async def agent_loop(session, tools, user_query):
    # åˆå§‹åŒ–å¯¹è¯å†å²
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_query}
    ]
    
    openai_tools = format_mcp_tools_for_openai(tools)
    max_turns = 15 # é˜²æ­¢æ­»å¾ªç¯
    
    print(f"\nğŸ§  Agent æ”¶åˆ°ä»»åŠ¡: {user_query}")

    for turn in range(max_turns):
        print(f"\nğŸ”„ [ç¬¬ {turn + 1} å›åˆ] æ€è€ƒä¸­...")
        
        # A. è°ƒç”¨ LLM
        try:
            response = client.chat.completions.create(
                model="qwen3-8b", 
                messages=messages,
                tools=openai_tools,
                temperature=0.1, 
            )
        except Exception as e:
            print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            return None

        message = response.choices[0].message
        content = message.content
        tool_calls = message.tool_calls

        # å°† LLM çš„å›å¤åŠ å…¥å†å²ï¼ˆéå¸¸é‡è¦ï¼Œå¦åˆ™ä¸‹ä¸€è½®ä¼šæŠ¥é”™ï¼‰
        messages.append(message)

        # B. æƒ…å†µ 1: LLM è¯·æ±‚è°ƒç”¨å·¥å…·
        if tool_calls:
            print(f"ï¿½ï¸  Agent å†³å®šè°ƒç”¨å·¥å…·: {[t.function.name for t in tool_calls]}")
            
            for tool_call in tool_calls:
                func_name = tool_call.function.name
                func_args_str = tool_call.function.arguments
                call_id = tool_call.id
                
                try:
                    func_args = json.loads(func_args_str)
                except json.JSONDecodeError:
                    print(f"âš ï¸ å‚æ•°è§£æé”™è¯¯: {func_args_str}")
                    func_args = {}

                print(f"   â¤ æ‰§è¡Œ: {func_name}({func_args})")
                
                # --- çœŸæ­£çš„ MCP è°ƒç”¨ ---
                try:
                    # session.call_tool è¿”å›çš„æ˜¯ CallToolResult å¯¹è±¡
                    mcp_result = await session.call_tool(func_name, arguments=func_args)
                    
                    # æå–æ–‡æœ¬å†…å®¹
                    tool_output_text = ""
                    if mcp_result.content:
                        for content_item in mcp_result.content:
                            if content_item.type == "text":
                                tool_output_text += content_item.text
                    
                    # æˆªæ–­è¿‡é•¿çš„è¾“å‡ºï¼ŒèŠ‚çœ token
                    if len(tool_output_text) > 2000:
                        tool_output_text = tool_output_text[:2000] + "...(å†…å®¹è¿‡é•¿å·²æˆªæ–­)"
                    
                    print(f"   âœ… ç»“æœ: {tool_output_text[:100]}...")

                except Exception as e:
                    tool_output_text = f"Error executing tool: {str(e)}"
                    print(f"   âŒ å·¥å…·æ‰§è¡Œå‡ºé”™: {e}")

                # å°†å·¥å…·æ‰§è¡Œç»“æœä½œä¸º 'tool' è§’è‰²æ¶ˆæ¯è¿”å›ç»™ LLM
                messages.append({
                    "role": "tool",
                    "tool_call_id": call_id,
                    "content": tool_output_text
                })
            
            # å·¥å…·æ‰§è¡Œå®Œï¼Œç›´æ¥è¿›å…¥ä¸‹ä¸€è½®å¾ªç¯ï¼Œè®© LLM çœ‹åˆ°ç»“æœå¹¶ç»§ç»­æ€è€ƒ
            continue

        # C. æƒ…å†µ 2: LLM æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œå¯èƒ½æ˜¯è¾“å‡ºäº†æœ€ç»ˆç»“æœ
        if content:
            # å°è¯•è§£æ JSON
            cleaned_content = content.replace("```json", "").replace("```", "").strip()
            # å°è¯•ç®€å•æ¸…æ´—å¼€å¤´ç»“å°¾
            if cleaned_content.startswith("json"):
                 cleaned_content = cleaned_content[4:].strip()

            try:
                data = json.loads(cleaned_content)
                print("\nâœ¨ JSON è§£ææˆåŠŸï¼")
                return data # æˆåŠŸç»“æŸ
            except json.JSONDecodeError:
                # åªæœ‰å½“çœ‹èµ·æ¥åƒæ˜¯ç”±äºæ ¼å¼é”™è¯¯å¯¼è‡´è§£æå¤±è´¥æ—¶æ‰é‡è¯•
                if "[" in cleaned_content or "{" in cleaned_content:
                     print(f"âš ï¸ JSON è§£æå¤±è´¥ï¼Œå°è¯•è®© Agent ä¿®å¤...")
                     error_msg = "ä½ çš„å›å¤æ— æ³•è§£æä¸ºæ ‡å‡†çš„ JSONã€‚è¯·ä¸è¦è¾“å‡º Markdownï¼Œåªè¾“å‡º JSON å†…å®¹ (ä¾‹å¦‚ [...])ã€‚"
                     messages.append({"role": "user", "content": error_msg})
                else:
                    # å¯èƒ½æ˜¯æ™®é€šçš„å¯¹è¯å›å¤ï¼Œä¸æ˜¯ JSON
                    print(f"ğŸ¤– Agent: {content}")
                    # è‡ªåŠ¨æç¤ºå®ƒï¼šè¯·å¼€å§‹æ‰§è¡Œæˆ–è¾“å‡º JSON
                    # messages.append({"role": "user", "content": "è¯·ç»§ç»­..."})
                    pass
    
    print("âŒ è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä»»åŠ¡æœªå®Œæˆã€‚")
    return None

async def run_smart_agent():
    # 1. å¯åŠ¨ MCP Server
    server_params = StdioServerParameters(
        command=sys.executable, 
        args=["resume_server.py"], 
        env=os.environ.copy()
    )

    print(f"ğŸ”Œ æ­£åœ¨å¯åŠ¨ MCP Server ({sys.executable})...")
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            # è·å–å·¥å…·
            tools = await session.list_tools()
            print(f"ğŸ”§ æ¿€æ´»å·¥å…·: {[t.name for t in tools.tools]}")
            
            # å¼€å§‹ä»»åŠ¡
            # æ³¨æ„ï¼šæˆ‘åœ¨ Prompt é‡ŒæŒ‡å®šäº†å» resumes ç›®å½•æ‰¾
            final_json = await agent_loop(session, tools.tools, "è¯·ç­›é€‰ resumes ç›®å½•ä¸‹çš„ç®€å†ï¼Œæ‰¾å‡ºé€‚åˆåš Python å¼€å‘çš„å€™é€‰äººã€‚")
            
            if final_json:
                print("\n================ æœ€ç»ˆç»“æœ ================")
                print(json.dumps(final_json, indent=4, ensure_ascii=False))
                print("==========================================")
                
                # å¯é€‰ï¼šä¿å­˜åˆ°æ–‡ä»¶
                with open("filtered_resumes.json", "w", encoding="utf-8") as f:
                     json.dump(final_json, f, indent=4, ensure_ascii=False)
                print("å·²ä¿å­˜åˆ° filtered_resumes.json")

if __name__ == "__main__":
    asyncio.run(run_smart_agent())