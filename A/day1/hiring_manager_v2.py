# -*- coding: utf-8 -*-
import os
import sys
import json
import requests

# ç¡®ä¿æ ‡å‡†è¾“å‡ºä½¿ç”¨ UTF-8 ç¼–ç 
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')
if sys.stdin.encoding != 'utf-8':
    sys.stdin.reconfigure(encoding='utf-8')

# ==========================================
# ğŸ”§ é…ç½®åŒºåŸŸ (è¯·æŒ‰ç…§ä½ çš„å®é™…æƒ…å†µä¿®æ”¹)
# ==========================================

# 1. æœ¬åœ° LLM Studio çš„ API Key (é€šå¸¸å¯ä»¥æ˜¯ä»»æ„å€¼)
api_key = os.getenv("OPENAI_API_KEY", "lm-studio")

# 2. æœ¬åœ° LLM æœåŠ¡åœ°å€
base_url = "http://127.0.0.1:33333/v1/chat/completions"

# 3. æ¨¡å‹åç§°
model_name = "gpt-3.5-turbo"

def call_llm(messages):
    """è°ƒç”¨ LLM API"""
    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": f"Bearer {api_key}"
    }
    
    data = {
        "model": model_name,
        "messages": messages,
        "temperature": 0.7
    }
    
    try:
        response = requests.post(
            base_url,
            headers=headers,
            json=data,
            timeout=30
        )
        response.raise_for_status()
        result = response.json()
        return result['choices'][0]['message']['content']
    except Exception as e:
        raise Exception(f"API è°ƒç”¨å¤±è´¥: {e}")

def chat_with_hiring_manager():
    print("------------------------------------------------------")
    print("ğŸ‘¨â€ğŸ’¼ é¢è¯•å®˜: è¿™é‡Œçš„ç®€å†å †ç§¯å¦‚å±±ï¼Œä½ æœ€å¥½è¨€ç®€æ„èµ…ã€‚è¯·è¿›ã€‚")
    print("------------------------------------------------------")

    # å®šä¹‰"äººè®¾" (System Prompt)
    system_prompt = "ä½ æ˜¯ä¸€ä½æ€§æ ¼ä¸¥å‰ã€ä¸è‹Ÿè¨€ç¬‘çš„æŠ€æœ¯æ‹›è˜ç»ç†ã€‚ä½ åªå…³å¿ƒæ±‚èŒè€…çš„æŠ€æœ¯èƒ½åŠ›å’Œè¿‡å¾€ç»éªŒã€‚æ— è®ºç”¨æˆ·è¯´ä»€ä¹ˆï¼Œä½ éƒ½è¦ä¿æŒè¿™ç§ä¸“ä¸šä¸”ç•¥å¸¦æŒ‘å‰”çš„å£å»ã€‚ä¸è¦è·³å‡ºè§’è‰²ã€‚"

    # ç®€å•çš„å¯¹è¯å†å² (è®© AI è®°å¾—ä¹‹å‰çš„å¯¹è¯)
    messages = [
        {"role": "system", "content": system_prompt}
    ]

    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input("\nğŸ‘¤ æ±‚èŒè€… (ä½ ): ")
            
            # é€€å‡ºæ¡ä»¶
            if user_input.lower() in ["exit", "quit", "é€€å‡º", "å†è§"]:
                print("\nğŸ‘¨â€ğŸ’¼ é¢è¯•å®˜: è¡Œäº†,ä»Šå¤©çš„é¢è¯•åˆ°æ­¤ç»“æŸã€‚å›å»ç­‰é€šçŸ¥å§ã€‚")
                break

            # å°†ç”¨æˆ·çš„è¯åŠ å…¥å†å²
            messages.append({"role": "user", "content": user_input})

            # è°ƒç”¨å¤§æ¨¡å‹ (API Call)
            ai_reply = call_llm(messages)

            # æ˜¾ç¤ºå›å¤
            print(f"\nğŸ‘¨â€ğŸ’¼ é¢è¯•å®˜: {ai_reply}")

            # å°† AI çš„å›å¤ä¹ŸåŠ å…¥å†å²,å½¢æˆå¤šè½®å¯¹è¯
            messages.append({"role": "assistant", "content": ai_reply})

        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            print("è¯·æ£€æŸ¥ä½ çš„ API Key å’Œç½‘ç»œé…ç½®ã€‚")
            break

if __name__ == "__main__":
    chat_with_hiring_manager()
