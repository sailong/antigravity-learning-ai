# -*- coding: utf-8 -*-
import os
import sys
import locale
import json

# è®¾ç½®ç¯å¢ƒç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'
locale.setlocale(locale.LC_ALL, '')

if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
if hasattr(sys.stdin, 'reconfigure'):
    sys.stdin.reconfigure(encoding='utf-8')

from openai import OpenAI

# ==========================================
# ğŸ”§ é…ç½®
# ==========================================

api_key = os.getenv("OPENAI_API_KEY", "lm-studio")
base_url = "http://127.0.0.1:33333/v1"
model_name = "qwen/qwen3-vl-8b"

client = OpenAI(api_key=api_key, base_url=base_url)

# ==========================================
# ğŸ“¦ å®šä¹‰å¯ç”¨çš„å‡½æ•° (å·¥å…·ç®±)
# ==========================================

def get_weather(city):
    """è·å–å¤©æ°”ä¿¡æ¯ (æ¨¡æ‹Ÿæ•°æ®)"""
    weather_data = {
        "åŒ—äº¬": {"weather": "æ™´å¤©", "temperature": "15Â°C", "humidity": "45%"},
        "ä¸Šæµ·": {"weather": "å¤šäº‘", "temperature": "18Â°C", "humidity": "60%"},
        "å¹¿å·": {"weather": "å°é›¨", "temperature": "22Â°C", "humidity": "75%"},
        "æ·±åœ³": {"weather": "æ™´å¤©", "temperature": "25Â°C", "humidity": "55%"}
    }
    
    if city in weather_data:
        data = weather_data[city]
        return json.dumps(data, ensure_ascii=False)
    else:
        return json.dumps({"error": f"{city}çš„å¤©æ°”æ•°æ®æš‚æ—¶æ— æ³•è·å–"}, ensure_ascii=False)

def calculate(expression):
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    try:
        # å®‰å…¨çš„è®¡ç®—,åªå…è®¸åŸºæœ¬è¿ç®—
        allowed_chars = set("0123456789+-*/.()")
        if not all(c in allowed_chars or c.isspace() for c in expression):
            return json.dumps({"error": "è¡¨è¾¾å¼åŒ…å«ä¸å…è®¸çš„å­—ç¬¦"}, ensure_ascii=False)
        
        result = eval(expression)
        return json.dumps({"expression": expression, "result": result}, ensure_ascii=False)
    except Exception as e:
        return json.dumps({"error": f"è®¡ç®—é”™è¯¯: {str(e)}"}, ensure_ascii=False)

# å‡½æ•°æ³¨å†Œè¡¨
AVAILABLE_FUNCTIONS = {
    "get_weather": get_weather,
    "calculate": calculate
}

# ==========================================
# ğŸ› ï¸ å®šä¹‰å‡½æ•°æè¿° (å‘Šè¯‰ AI æœ‰å“ªäº›å·¥å…·)
# ==========================================

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ä¿¡æ¯,åŒ…æ‹¬å¤©æ°”çŠ¶å†µã€æ¸©åº¦å’Œæ¹¿åº¦",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°,ä¾‹å¦‚: åŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³"
                    }
                },
                "required": ["city"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "calculate",
            "description": "è®¡ç®—æ•°å­¦è¡¨è¾¾å¼,æ”¯æŒåŠ å‡ä¹˜é™¤å’Œæ‹¬å·",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "æ•°å­¦è¡¨è¾¾å¼,ä¾‹å¦‚: 123 + 456, (10 * 5) - 3"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]

# ==========================================
# ğŸ¤– ä¸»å‡½æ•°: å¤„ç†ç”¨æˆ·é—®é¢˜
# ==========================================

def chat_with_function_calling(user_question):
    """
    ä½¿ç”¨ Function Calling å¤„ç†ç”¨æˆ·é—®é¢˜
    """
    print(f"\nğŸ‘¤ ç”¨æˆ·: {user_question}")
    print("=" * 60)
    
    # åˆå§‹åŒ–å¯¹è¯å†å²
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹,å¯ä»¥å¸®åŠ©ç”¨æˆ·æŸ¥è¯¢å¤©æ°”å’Œè¿›è¡Œæ•°å­¦è®¡ç®—ã€‚å½“ç”¨æˆ·è¯¢é—®å¤©æ°”æˆ–éœ€è¦è®¡ç®—æ—¶,è¯·ä½¿ç”¨ç›¸åº”çš„å·¥å…·ã€‚"
        },
        {
            "role": "user",
            "content": user_question
        }
    ]
    
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ AI
    print("ğŸ¤– AI æ­£åœ¨åˆ†æé—®é¢˜...")
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=messages,
            tools=tools,
            tool_choice="auto",  # è®© AI è‡ªåŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å‡½æ•°
            temperature=0.3
        )
        
        assistant_message = response.choices[0].message
        
        # æ£€æŸ¥ AI æ˜¯å¦è¦è°ƒç”¨å‡½æ•°
        if assistant_message.tool_calls:
            print(f"ğŸ’¡ AI å†³å®šè°ƒç”¨å‡½æ•°!")
            
            # å°† AI çš„å›å¤åŠ å…¥å†å²
            messages.append(assistant_message)
            
            # å¤„ç†æ¯ä¸ªå‡½æ•°è°ƒç”¨
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                print(f"\nğŸ“ è°ƒç”¨å‡½æ•°: {function_name}")
                print(f"ğŸ“‹ å‚æ•°: {json.dumps(function_args, ensure_ascii=False)}")
                
                # æ‰§è¡Œå‡½æ•°
                function_to_call = AVAILABLE_FUNCTIONS.get(function_name)
                if function_to_call:
                    function_result = function_to_call(**function_args)
                    print(f"âš™ï¸  æ‰§è¡Œç»“æœ: {function_result}")
                    
                    # å°†å‡½æ•°ç»“æœåŠ å…¥å¯¹è¯å†å²
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": function_name,
                        "content": function_result
                    })
                else:
                    print(f"âŒ é”™è¯¯: å‡½æ•° '{function_name}' ä¸å­˜åœ¨")
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨ AI,è®©å®ƒæ ¹æ®å‡½æ•°ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
            print("\nğŸ¤– AI æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›å¤...")
            second_response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=0.3
            )
            
            final_reply = second_response.choices[0].message.content
            print(f"\nğŸ’¬ AI å›å¤: {final_reply}")
            
        else:
            # AI ä¸éœ€è¦è°ƒç”¨å‡½æ•°,ç›´æ¥å›å¤
            print(f"\nğŸ’¬ AI å›å¤: {assistant_message.content}")
    
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

# ==========================================
# ğŸš€ ä¸»ç¨‹åº
# ==========================================

def main():
    print("=" * 60)
    print("ğŸ¤– Function Calling æ™ºèƒ½åŠ©æ‰‹")
    print("=" * 60)
    print("\næˆ‘å¯ä»¥å¸®ä½ :")
    print("  1. æŸ¥è¯¢å¤©æ°” (æ”¯æŒ: åŒ—äº¬ã€ä¸Šæµ·ã€å¹¿å·ã€æ·±åœ³)")
    print("  2. è¿›è¡Œæ•°å­¦è®¡ç®—")
    print("\nè¾“å…¥ 'quit' é€€å‡ºç¨‹åº\n")
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?",
        "å¸®æˆ‘ç®—ä¸€ä¸‹ (123 + 456) * 2",
        "ä¸Šæµ·å’Œå¹¿å·å“ªä¸ªåŸå¸‚æ¸©åº¦æ›´é«˜?"
    ]
    
    print("ğŸ“ ç¤ºä¾‹é—®é¢˜:")
    for i, q in enumerate(test_questions, 1):
        print(f"  {i}. {q}")
    
    while True:
        print("\n" + "-" * 60)
        user_input = input("\nğŸ’¬ è¯·è¾“å…¥é—®é¢˜ (æˆ–è¾“å…¥ quit é€€å‡º): ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
            print("\nğŸ‘‹ å†è§!")
            break
        
        if not user_input:
            print("âš ï¸  è¾“å…¥ä¸èƒ½ä¸ºç©º")
            continue
        
        chat_with_function_calling(user_input)

if __name__ == "__main__":
    main()
